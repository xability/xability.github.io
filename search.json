[
  {
    "objectID": "braille-display.html",
    "href": "braille-display.html",
    "title": "How to Request an NLS eReader Braille Display?",
    "section": "",
    "text": "Some of the studies we conduct here at the (x)Ability Design Lab have an eligibility criterion requiring perspective participants to have access to a refreshable braille display. While companies like Orbit Research offer these devices at a relatively lower cost when compared with what’s on the market, we understand that a no-cost solution may be more ideal depending on an individual’s current situation. This is why we have put together this guide to walk you through the process to request and receive a refreshable braille display from the National Library Service for the Blind and Print Disabled (NLS).\nSome important things to note: * You must be an NLS patron. * Availability of the refreshable braille display eReaders from the NLS is not guaranteed. * While there is no cost associated, patrons are loaning these eReaders from the NLS for an unspecified period of time."
  },
  {
    "objectID": "braille-display.html#purpose-of-this-page",
    "href": "braille-display.html#purpose-of-this-page",
    "title": "How to Request an NLS eReader Braille Display?",
    "section": "",
    "text": "Some of the studies we conduct here at the (x)Ability Design Lab have an eligibility criterion requiring perspective participants to have access to a refreshable braille display. While companies like Orbit Research offer these devices at a relatively lower cost when compared with what’s on the market, we understand that a no-cost solution may be more ideal depending on an individual’s current situation. This is why we have put together this guide to walk you through the process to request and receive a refreshable braille display from the National Library Service for the Blind and Print Disabled (NLS).\nSome important things to note: * You must be an NLS patron. * Availability of the refreshable braille display eReaders from the NLS is not guaranteed. * While there is no cost associated, patrons are loaning these eReaders from the NLS for an unspecified period of time."
  },
  {
    "objectID": "braille-display.html#how-to-request-an-nls-refreshable-braille-display-ereader",
    "href": "braille-display.html#how-to-request-an-nls-refreshable-braille-display-ereader",
    "title": "How to Request an NLS eReader Braille Display?",
    "section": "How to Request an NLS Refreshable Braille Display (eReader)",
    "text": "How to Request an NLS Refreshable Braille Display (eReader)\n\nIf you are not one already, enroll to become an NLS patron. Be sure to refer to the eligibility criteria and steps outlined on that page before you apply.\nOnce you are enrolled by the NLS as a patron and have access to their services, find your network library’s contact information from this page.\nOnce you have identified your regional library, give them a call and ask them if you can request an NLS refreshable braille display eReader to read books from BARD.\nIf they are still accepting requests for these eReaders, they’ll take down your name, mailing address, and any other relevant information. Please ensure that you provide them with a mailing address that you feel comfortable having the braille display sent to.\nIt will take anywhere between 1 to 4 weeks for them to process your request and mail you the loaner eReader. This estimate may have changed since we went through the process in Q2 of 2024.\nOnce you receive the device, feel free to reference the enclosed materials like the User Guide. You’ll want to connect the device to your computer to meet our eligibility criterion for some of our ongoing studies.\n\nFor more information about this process, or to learn about available NLS equipment and other device recommendations from the NLSk, check out this Equipment for NLS Materials page.\nIf you have any questions or concerns, please email xability-lab@illinois.edu, and include NLS, all caps in the subject line.\nWe thank you for your expressed interest in our research and look forward to your participation in our ongoing studies.\nThis guide was last updated on September 24, 2024 at 9 PM CDT"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "The following includes the recent publications in our lab (including outcomes with other collaborators).\n\n\n1. Pillai, A. (n.d.). Accessible Usability Scale (AUS). In Fable. https://makeitfable.com/accessible-usability-scale/.\n\n\n2. Thematic Analysis: Striving to Meet the Trustworthiness Criteria - Lorelli S. Nowell, Jill M. Norris, Deborah E. White, Nancy J. Moules, 2017. (n.d.). https://journals.sagepub.com/doi/10.1177/1609406917733847.\n\n\n3. Seo, J. Y., O’Modhrain, S., Xia, Y., Kamath, S. S., Lee, B., & Coughlan, J. (2024). Designing Born-Accessible Courses in Data Science and Visualization: Challenges and Opportunities of a Remote Curriculum Taught by Blind Instructors to Blind Students. EuroVis 2024 - Education Papers. https://doi.org/10.2312/EVED.20241053\n\n\n4. Seo, J., Xia, Y., Lee, B., Mccurry, S., & Yam, Y. J. (2024). MAIDR: Making Statistical Visualizations Accessible with Multimodal Data Representation. Proceedings of the CHI Conference on Human Factors in Computing Systems, 1–22. https://doi.org/10.1145/3613904.3642730\n\n\n5. Seo, J., & Rogge, M. (2023). Coding Non-Visually in Visual Studio Code: Collaboration Towards Accessible Development Environment for Blind Programmers. Proceedings of the 25th International ACM SIGACCESS Conference on Computers and Accessibility, 1–9. https://doi.org/10.1145/3597638.3614550\n\n\n6. Sharif, A., McCall, A. L., & Bolante, K. R. (2022). Should I Say “Disabled People” or “People with Disabilities”? Language Preferences of Disabled People Between Identity- and Person-First Language. Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility, 1–18. https://doi.org/10.1145/3517428.3544813\n\n\n7. Spiel, K., Gerling, K., Bennett, C. L., Brulé, E., Williams, R. M., Rode, J., & Mankoff, J. (2020). Nothing About Us Without Us: Investigating the Role of Critical Disability Studies in HCI. Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, 1–8. https://doi.org/10.1145/3334480.3375150\n\n\n8. Virani, A. (2020). Building the Accessible Usability Scale - A Walkthrough. In Fable. https://makeitfable.com/article/building-the-accessible-usability-scale/.\n\n\n9. Bennett, C. L., Brady, E., Branham, S. M., & Yam, Y. J. (2018). Interdependence as a Frame for Assistive Technology Research and Design. Proceedings of the 20th International ACM SIGACCESS Conference on Computers and Accessibility, 161–173. https://doi.org/10.1145/3234695.3236348\n\n\n10. Caine, K. (2016). Local Standards for Sample Size at CHI. Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, 981–992. https://doi.org/10.1145/2858036.2858498\n\n\n11. Faulkner, L. (2003). Beyond the five-user assumption: Benefits of increased sample sizes in usability testing. Behavior Research Methods, Instruments, & Computers, 35(3), 379–383. https://doi.org/10.3758/BF03195514"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The symbol “(x)” in our lab’s name is an experience variable and the testament to our multifaceted approach towards inclusivity and accessibility:\nBy focusing on (x)Ability rather than (dis)Ability, we aim to unlock each person’s unlimited potential. Our lab is driven by the principle of designing with, by, for, and of people with (dis)Abilities. We strive to remove the “(x)”—the barriers—from people with (dis)Abilities, facilitating their access to information systems and contributing to a more inclusive world."
  },
  {
    "objectID": "about.html#our-mission",
    "href": "about.html#our-mission",
    "title": "About",
    "section": "Our Mission",
    "text": "Our Mission\nOur mission is to advance the field of inclusive UX and LX design by: - Conducting groundbreaking research that addresses the challenges faced by people with (dis)Abilities. - Developing tools and methods that enhance the accessibility of digital environments. - Collaborating with communities to ensure our solutions are informed by the real needs and experiences of people with (dis)Abilities.\nJoin us in redefining accessibility and inclusivity at the (x)Ability Design Lab. Because everyone deserves to experience the world without barriers."
  },
  {
    "objectID": "people.html",
    "href": "people.html",
    "title": "People",
    "section": "",
    "text": "Dr. JooYoung Seo leads the (x)Ability Design Lab, where their research focuses on accessibility research. He is an assistant professor in the School of Information Sciences and a faculty affiliate in the Department of Computer Science, Informatics Institute, and the National Center for Supercomputing Applications at the University of Illinois Urbana-Champaign. Seo is also an RStudio double-certified data science instructor and accessibility expert certified by the International Association of Accessibility Professionals (IAAP). His research topics involve accessible computing, universal design, inclusive data science, and equitable healthcare technologies. As an emerging learning scientist and information scientist, his research focuses particularly on how to make computational literacy more accessible to people with dis/abilities by using multimodal data representation.\nHe has worked on various research and development projects on accessible computing and open-source data science packages (e.g., gt; shiny; rmarkdown to name a few) for accessibility. His research projects have involved not just web accessibility, but also human-centered design and development studies, including inclusive makerspaces, tangible block-based programming, accessible data science (e.g., data tactualization, sonification, and verbalization), and accessible/reproducible scientific writing tools for people with and without dis/abilities.\nHis research is funded by national institutes, industrial partners, and academic society, such as Institute of Museum and Library Services (IMLS), National Science Foundation (NSF), National Institute on Disability, Independent Living, and Rehabilitation Research (NIDILRR), Posit Software, PBC (formerly RStudio), Teach Access, and the International Society of the Learning Sciences (ISLS) and the Wallace Foundation.\nSeo obtained his PhD and M.Ed in at the Pennsylvania State University, and double BA in education and English literature from Sungkyunkwan University, Seoul, South Korea."
  },
  {
    "objectID": "people.html#director",
    "href": "people.html#director",
    "title": "People",
    "section": "",
    "text": "Dr. JooYoung Seo leads the (x)Ability Design Lab, where their research focuses on accessibility research. He is an assistant professor in the School of Information Sciences and a faculty affiliate in the Department of Computer Science, Informatics Institute, and the National Center for Supercomputing Applications at the University of Illinois Urbana-Champaign. Seo is also an RStudio double-certified data science instructor and accessibility expert certified by the International Association of Accessibility Professionals (IAAP). His research topics involve accessible computing, universal design, inclusive data science, and equitable healthcare technologies. As an emerging learning scientist and information scientist, his research focuses particularly on how to make computational literacy more accessible to people with dis/abilities by using multimodal data representation.\nHe has worked on various research and development projects on accessible computing and open-source data science packages (e.g., gt; shiny; rmarkdown to name a few) for accessibility. His research projects have involved not just web accessibility, but also human-centered design and development studies, including inclusive makerspaces, tangible block-based programming, accessible data science (e.g., data tactualization, sonification, and verbalization), and accessible/reproducible scientific writing tools for people with and without dis/abilities.\nHis research is funded by national institutes, industrial partners, and academic society, such as Institute of Museum and Library Services (IMLS), National Science Foundation (NSF), National Institute on Disability, Independent Living, and Rehabilitation Research (NIDILRR), Posit Software, PBC (formerly RStudio), Teach Access, and the International Society of the Learning Sciences (ISLS) and the Wallace Foundation.\nSeo obtained his PhD and M.Ed in at the Pennsylvania State University, and double BA in education and English literature from Sungkyunkwan University, Seoul, South Korea."
  },
  {
    "objectID": "people.html#ph.d.-students",
    "href": "people.html#ph.d.-students",
    "title": "People",
    "section": "Ph.D. Students",
    "text": "Ph.D. Students\n\n\n\n\n\n\nSanchita Kamath\n\n\nPh.D. Student, Information Sciences\n\n\n\n\nHer research focuses on designing and developing immersive, user-centered solutions that enhance accessibility and inclusivity, particularly for blind and low-vision (BLV) individuals. With a background in Computer Science and Engineering, Sanchita’s work seeks to bridge the gap between cutting-edge technology and user experience. She is currently working on studies that investigate cognition in BLV people and multiple tools and technologies through which this can be achieved.\n\n\n\n\n\n\n\n\n\nAziz N. Zeidieh\n\n\nPh.D. Student, Informatics\n\n\n\n\nAziz is a data-driven human-computer interaction researcher working at the intersection of orientation and mobility, artificial intelligence, and assistive technology. His current work focuses on utilizing multimodal AI models to provide an accessible and interactive application for the spatial orientation of blind and visually impaired (BVI) travelers. He is actively exploring opportunities to leverage data and the lived experiences of BVI individuals to facilitate safer and more efficient technologically interdependent travel experiences.\n\n\n\n\n\n\n\n\n\nOmar Khan\n\n\nPh.D. Student, Computer Science\n\n\n\n\nOmar is a human-computer interaction researcher working at the intersection of accessibility, mental health and wellness, and artificial intelligence. His current research investigates the usefulness of existing digital mental health tracking services throughout the blind and low-vision (BLV) community and how they might be improved for greater accessibility, utility, and inclusivity. He is also continually exploring opportunities to leverage emerging technologies such as large language models (LLMs), co-designing these experiences with the BLV community to provide personalized mental health support."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "(x)Ability Design Lab",
    "section": "",
    "text": "Welcome to the (x)Ability Design Lab, pronounced as “Accessibility Design” Lab, where the “x” embodies our mission to enhance user experience (UX) and learning experience (LX) by dismantling sociotechnical barriers associated with disability. At our core, we believe in focusing on the ability and experience of all individuals, moving beyond the constraints of traditional accessibility discourse."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact Us",
    "section": "",
    "text": "If you would like to discuss a project or have any questions, please feel free to email us at xability-lab@illinois.edu."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Researchers at NewHaptics Corporation and the University of Illinois at Urbana-Champaign are developing and testing software and hardware tools for faculty, staff, postdoctoral research fellows, and graduate students who are blind or have low vision, and who are working in college and university Chemistry, Mathematics, and Computer Science and Engineering and Information Sciences employment settings. These tools, which use a combination of hearing and touch technologies, are making it possible for people who are blind or have low vision to generate, identify, and manipulate digital data patterns and trends.\nGiven the scarcity of STEM scientists, researchers, and educators in our country, opportunities to increase knowledge about better data use technologies is essential to the retention and advancement of students and professionals who are blind or have low vision.\n\n\n\nDevelop new hardware interaction components and firmware/drivers;\nDevelop new interaction software, and\nEvaluate the system and conduct workshops for users.\n\nThe project activities are addressing the following key research questions: 1) How can the addition of spatial information, realized through multiline braille and large array tactile graphics hardware, coupled with interactive software tools, break down barriers to data use? 2) What design considerations contribute to multi-modal data, that is, verbal, sonification, and tactile data representations that go beyond a single perceptual modality? Answers to these questions have the potential to contribute to research about STEM postsecondary workplace solutions for people with disabilities."
  },
  {
    "objectID": "projects.html#an-audiotactile-data-system-for-blind-or-low-vision-faculty-staff-postdocs-and-graduate-students-in-chemistry-math-computer-and-information-sciences",
    "href": "projects.html#an-audiotactile-data-system-for-blind-or-low-vision-faculty-staff-postdocs-and-graduate-students-in-chemistry-math-computer-and-information-sciences",
    "title": "Projects",
    "section": "",
    "text": "Researchers at NewHaptics Corporation and the University of Illinois at Urbana-Champaign are developing and testing software and hardware tools for faculty, staff, postdoctoral research fellows, and graduate students who are blind or have low vision, and who are working in college and university Chemistry, Mathematics, and Computer Science and Engineering and Information Sciences employment settings. These tools, which use a combination of hearing and touch technologies, are making it possible for people who are blind or have low vision to generate, identify, and manipulate digital data patterns and trends.\nGiven the scarcity of STEM scientists, researchers, and educators in our country, opportunities to increase knowledge about better data use technologies is essential to the retention and advancement of students and professionals who are blind or have low vision.\n\n\n\nDevelop new hardware interaction components and firmware/drivers;\nDevelop new interaction software, and\nEvaluate the system and conduct workshops for users.\n\nThe project activities are addressing the following key research questions: 1) How can the addition of spatial information, realized through multiline braille and large array tactile graphics hardware, coupled with interactive software tools, break down barriers to data use? 2) What design considerations contribute to multi-modal data, that is, verbal, sonification, and tactile data representations that go beyond a single perceptual modality? Answers to these questions have the potential to contribute to research about STEM postsecondary workplace solutions for people with disabilities."
  },
  {
    "objectID": "projects.html#maidr-multimodal-access-and-interactive-data-representation",
    "href": "projects.html#maidr-multimodal-access-and-interactive-data-representation",
    "title": "Projects",
    "section": "MAIDR: Multimodal Access and Interactive Data Representation",
    "text": "MAIDR: Multimodal Access and Interactive Data Representation\nAssistant Professor JooYoung Seo has been awarded a $649,921 Early Career Development grant from the Institute of Museum and Library Services, under the Laura Bush 21st Century Librarian Program, which supports “developing a diverse workforce of librarians to better meet the changing learning and information needs of the American public by enhancing the training and professional development of librarians, developing faculty and library leaders, and recruiting and educating the next generation of librarians.”\nThe three-year grant is an extension of Seo’s ongoing project, “MAIDR: Multimodal Access and Interactive Data Representation,” that has received support from the International Society of the Learning Sciences and the Wallace Foundation. Through the initial work, Seo has been developing computer tools that augment visual charts with touchable (braille), readable (text), and audible (sound) representations, to make them more accessible for the visually impaired. In the new project, Seo’s tools will connect the multimodal and accessible data representation with data curators’ day-to-day reproducible workflows, integrating them into reproducible frameworks (e.g., Jupyter Notebook, R Markdown, Quarto) and visualization libraries (e.g., R ggplot2, Python matplotlib).\n“Multimodal data representation is not merely an innovation; it is an imperative for inclusivity,” Seo said. “While data visualization is a dominant method in scientific representation, it inherently marginalizes those who are blind and visually impaired, essentially sidelining them from full participation in the scientific discourse. My multimodal data representation challenges this norm by expanding the toolkit beyond the visual. It incorporates auditory, tactile, and verbal methods, thereby democratizing access to knowledge.”\nAccording to Seo, this approach enriches the understanding of data for everyone and offers multiple perspectives that a singular approach could easily miss.\nThe new project will involve meeting with data curators to assess needs and with blind patrons to shape the tools being created. For that work, Seo will collaborate with his community partners, Data Curation Network (DCN) and the National Federation of the Blind (NFB).\nPartners on the project include the National Center for Supercomputing Applications (NCSA), Posit Public Benefit Corporation (FKA, RStudio), and the Chart2Music (C2M) open-source project team.\n\nIMLS grant RE-254891-OLS-23"
  },
  {
    "objectID": "projects.html#promoting-computational-thinking-skills-for-blind-and-visually-impaired-teens-through-accessible-library-makerspaces",
    "href": "projects.html#promoting-computational-thinking-skills-for-blind-and-visually-impaired-teens-through-accessible-library-makerspaces",
    "title": "Projects",
    "section": "Promoting Computational Thinking Skills for Blind and Visually Impaired Teens Through Accessible Library Makerspaces",
    "text": "Promoting Computational Thinking Skills for Blind and Visually Impaired Teens Through Accessible Library Makerspaces\nLibrary makerspaces offer community members the opportunity to tinker, design, experiment, and create with a range of technology in an informal learning space. However, because current makerspaces and maker tools are highly vision oriented, blind and visually impaired (BVI) people have limited access to these learning opportunities. A new project led by Assistant Professor JooYoung Seo and Associate Professor Kyungwon Koh, director of the CU Community Fab Lab, seeks to address this problem by creating accessible maker programs for BVI learners and developing training materials on accessible making for librarians and maker professionals. The researchers were recently awarded a three-year, $498,638 National Leadership Grant from the Institute of Museum and Library Services for their project, “Promoting Computational Thinking Skills for Blind and Visually Impaired Teens Through Accessible Library Makerspaces.”\nFor the project, the iSchool and CU Community Fab Lab will partner with the American Printing House for the Blind, Young Adult Library Services Association, and Reaching Across Illinois Library System Makerspace Networking Group. The research also has received support from the National Federation of the Blind (NFB) and the Disability Resources and Educational Services (DRES) and Information Accessibility Design and Policy (IADP) program at the University of Illinois. Activities will include training maker professionals and conducting an accessibility status assessment, hosting a summer camp with BVI teens to co-design accessible maker curriculum, testing the developed accessible maker programs in four Illinois library makerspaces, and training library users who will benefit from a more inclusive and accessible makerspace.\n“Just as curb cuts help more than a person who uses a wheelchair, accessibility features added to maker tools and learning materials can make the system more usable by everyone,” said Seo. “The tangible making activities and integrated curricula in our project will bring the current maker movement a new insight into how we can broaden the participation of maker and STEM learning for underserved populations of diverse abilities.”\nThe goal of the makerspace project is to not only enhance BVI learners’ computational thinking skills and STEM interests but also help librarians and maker professionals become more confident and capable when working with BVI populations.\n\nIMLS grant LG-252360-OLS-22"
  }
]