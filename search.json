[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The symbol “(x)” in our lab’s name is an experience variable and the testament to our multifaceted approach towards inclusivity and accessibility:\nBy focusing on (x)Ability rather than (dis)Ability, we aim to unlock each person’s unlimited potential. Our lab is driven by the principle of designing with, by, for, and of people with (dis)Abilities. We strive to remove the “(x)”—the barriers—from people with (dis)Abilities, facilitating their access to information systems and contributing to a more inclusive world."
  },
  {
    "objectID": "about.html#our-mission",
    "href": "about.html#our-mission",
    "title": "About",
    "section": "Our Mission",
    "text": "Our Mission\nOur mission is to advance the field of inclusive UX and LX design by: - Conducting groundbreaking research that addresses the challenges faced by people with (dis)Abilities. - Developing tools and methods that enhance the accessibility of digital environments. - Collaborating with communities to ensure our solutions are informed by the real needs and experiences of people with (dis)Abilities.\nJoin us in redefining accessibility and inclusivity at the (x)Ability Design Lab. Because everyone deserves to experience the world without barriers."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Researchers at NewHaptics Corporation and the University of Illinois at Urbana-Champaign are developing and testing software and hardware tools for faculty, staff, postdoctoral research fellows, and graduate students who are blind or have low vision, and who are working in college and university Chemistry, Mathematics, and Computer Science and Engineering and Information Sciences employment settings. These tools, which use a combination of hearing and touch technologies, are making it possible for people who are blind or have low vision to generate, identify, and manipulate digital data patterns and trends.\nGiven the scarcity of STEM scientists, researchers, and educators in our country, opportunities to increase knowledge about better data use technologies is essential to the retention and advancement of students and professionals who are blind or have low vision.\n\n\n\nDevelop new hardware interaction components and firmware/drivers;\nDevelop new interaction software, and\nEvaluate the system and conduct workshops for users.\n\nThe project activities are addressing the following key research questions: 1) How can the addition of spatial information, realized through multiline braille and large array tactile graphics hardware, coupled with interactive software tools, break down barriers to data use? 2) What design considerations contribute to multi-modal data, that is, verbal, sonification, and tactile data representations that go beyond a single perceptual modality? Answers to these questions have the potential to contribute to research about STEM postsecondary workplace solutions for people with disabilities."
  },
  {
    "objectID": "projects.html#an-audiotactile-data-system-for-blind-or-low-vision-faculty-staff-postdocs-and-graduate-students-in-chemistry-math-computer-and-information-sciences",
    "href": "projects.html#an-audiotactile-data-system-for-blind-or-low-vision-faculty-staff-postdocs-and-graduate-students-in-chemistry-math-computer-and-information-sciences",
    "title": "Projects",
    "section": "",
    "text": "Researchers at NewHaptics Corporation and the University of Illinois at Urbana-Champaign are developing and testing software and hardware tools for faculty, staff, postdoctoral research fellows, and graduate students who are blind or have low vision, and who are working in college and university Chemistry, Mathematics, and Computer Science and Engineering and Information Sciences employment settings. These tools, which use a combination of hearing and touch technologies, are making it possible for people who are blind or have low vision to generate, identify, and manipulate digital data patterns and trends.\nGiven the scarcity of STEM scientists, researchers, and educators in our country, opportunities to increase knowledge about better data use technologies is essential to the retention and advancement of students and professionals who are blind or have low vision.\n\n\n\nDevelop new hardware interaction components and firmware/drivers;\nDevelop new interaction software, and\nEvaluate the system and conduct workshops for users.\n\nThe project activities are addressing the following key research questions: 1) How can the addition of spatial information, realized through multiline braille and large array tactile graphics hardware, coupled with interactive software tools, break down barriers to data use? 2) What design considerations contribute to multi-modal data, that is, verbal, sonification, and tactile data representations that go beyond a single perceptual modality? Answers to these questions have the potential to contribute to research about STEM postsecondary workplace solutions for people with disabilities."
  },
  {
    "objectID": "projects.html#maidr-multimodal-access-and-interactive-data-representation",
    "href": "projects.html#maidr-multimodal-access-and-interactive-data-representation",
    "title": "Projects",
    "section": "MAIDR: Multimodal Access and Interactive Data Representation",
    "text": "MAIDR: Multimodal Access and Interactive Data Representation\nAssistant Professor JooYoung Seo has been awarded a $649,921 Early Career Development grant from the Institute of Museum and Library Services, under the Laura Bush 21st Century Librarian Program, which supports “developing a diverse workforce of librarians to better meet the changing learning and information needs of the American public by enhancing the training and professional development of librarians, developing faculty and library leaders, and recruiting and educating the next generation of librarians.”\nThe three-year grant is an extension of Seo’s ongoing project, “MAIDR: Multimodal Access and Interactive Data Representation,” that has received support from the International Society of the Learning Sciences and the Wallace Foundation. Through the initial work, Seo has been developing computer tools that augment visual charts with touchable (braille), readable (text), and audible (sound) representations, to make them more accessible for the visually impaired. In the new project, Seo’s tools will connect the multimodal and accessible data representation with data curators’ day-to-day reproducible workflows, integrating them into reproducible frameworks (e.g., Jupyter Notebook, R Markdown, Quarto) and visualization libraries (e.g., R ggplot2, Python matplotlib).\n“Multimodal data representation is not merely an innovation; it is an imperative for inclusivity,” Seo said. “While data visualization is a dominant method in scientific representation, it inherently marginalizes those who are blind and visually impaired, essentially sidelining them from full participation in the scientific discourse. My multimodal data representation challenges this norm by expanding the toolkit beyond the visual. It incorporates auditory, tactile, and verbal methods, thereby democratizing access to knowledge.”\nAccording to Seo, this approach enriches the understanding of data for everyone and offers multiple perspectives that a singular approach could easily miss.\nThe new project will involve meeting with data curators to assess needs and with blind patrons to shape the tools being created. For that work, Seo will collaborate with his community partners, Data Curation Network (DCN) and the National Federation of the Blind (NFB).\nPartners on the project include the National Center for Supercomputing Applications (NCSA), Posit Public Benefit Corporation (FKA, RStudio), and the Chart2Music (C2M) open-source project team.\n\nIMLS grant RE-254891-OLS-23"
  },
  {
    "objectID": "projects.html#promoting-computational-thinking-skills-for-blind-and-visually-impaired-teens-through-accessible-library-makerspaces",
    "href": "projects.html#promoting-computational-thinking-skills-for-blind-and-visually-impaired-teens-through-accessible-library-makerspaces",
    "title": "Projects",
    "section": "Promoting Computational Thinking Skills for Blind and Visually Impaired Teens Through Accessible Library Makerspaces",
    "text": "Promoting Computational Thinking Skills for Blind and Visually Impaired Teens Through Accessible Library Makerspaces\nLibrary makerspaces offer community members the opportunity to tinker, design, experiment, and create with a range of technology in an informal learning space. However, because current makerspaces and maker tools are highly vision oriented, blind and visually impaired (BVI) people have limited access to these learning opportunities. A new project led by Assistant Professor JooYoung Seo and Associate Professor Kyungwon Koh, director of the CU Community Fab Lab, seeks to address this problem by creating accessible maker programs for BVI learners and developing training materials on accessible making for librarians and maker professionals. The researchers were recently awarded a three-year, $498,638 National Leadership Grant from the Institute of Museum and Library Services for their project, “Promoting Computational Thinking Skills for Blind and Visually Impaired Teens Through Accessible Library Makerspaces.”\nFor the project, the iSchool and CU Community Fab Lab will partner with the American Printing House for the Blind, Young Adult Library Services Association, and Reaching Across Illinois Library System Makerspace Networking Group. The research also has received support from the National Federation of the Blind (NFB) and the Disability Resources and Educational Services (DRES) and Information Accessibility Design and Policy (IADP) program at the University of Illinois. Activities will include training maker professionals and conducting an accessibility status assessment, hosting a summer camp with BVI teens to co-design accessible maker curriculum, testing the developed accessible maker programs in four Illinois library makerspaces, and training library users who will benefit from a more inclusive and accessible makerspace.\n“Just as curb cuts help more than a person who uses a wheelchair, accessibility features added to maker tools and learning materials can make the system more usable by everyone,” said Seo. “The tangible making activities and integrated curricula in our project will bring the current maker movement a new insight into how we can broaden the participation of maker and STEM learning for underserved populations of diverse abilities.”\nThe goal of the makerspace project is to not only enhance BVI learners’ computational thinking skills and STEM interests but also help librarians and maker professionals become more confident and capable when working with BVI populations.\n\nIMLS grant LG-252360-OLS-22"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "The following includes the recent publications in our lab.\n\n\nBennett, C. L., Brady, E., Branham, S. M., & Yam, Y. J. (2018). Interdependence as a Frame for Assistive Technology Research and Design. Proceedings of the 20th International ACM SIGACCESS Conference on Computers and Accessibility, 161–173. https://doi.org/10.1145/3234695.3236348\n\n\nCaine, K. (2016). Local Standards for Sample Size at CHI. Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, 981–992. https://doi.org/10.1145/2858036.2858498\n\n\nFaulkner, L. (2003). Beyond the five-user assumption: Benefits of increased sample sizes in usability testing. Behavior Research Methods, Instruments, & Computers, 35(3), 379–383. https://doi.org/10.3758/BF03195514\n\n\nPillai, A. (n.d.). Accessible Usability Scale (AUS). In Fable. https://makeitfable.com/accessible-usability-scale/.\n\n\nSeo, J. Y., O’Modhrain, S., Xia, Y., Kamath, S. S., Lee, B., & Coughlan, J. (2024). Designing Born-Accessible Courses in Data Science and Visualization: Challenges and Opportunities of a Remote Curriculum Taught by Blind Instructors to Blind Students. EuroVis 2024 - Education Papers. https://doi.org/10.2312/EVED.20241053\n\n\nSeo, J., & Rogge, M. (2023). Coding Non-Visually in Visual Studio Code: Collaboration Towards Accessible Development Environment for Blind Programmers. Proceedings of the 25th International ACM SIGACCESS Conference on Computers and Accessibility, 1–9. https://doi.org/10.1145/3597638.3614550\n\n\nSeo, J., Xia, Y., Lee, B., Mccurry, S., & Yam, Y. J. (2024). MAIDR: Making Statistical Visualizations Accessible with Multimodal Data Representation. Proceedings of the CHI Conference on Human Factors in Computing Systems, 1–22. https://doi.org/10.1145/3613904.3642730\n\n\nSharif, A., McCall, A. L., & Bolante, K. R. (2022). Should I Say “Disabled People” or “People with Disabilities”? Language Preferences of Disabled People Between Identity- and Person-First Language. Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility, 1–18. https://doi.org/10.1145/3517428.3544813\n\n\nSpiel, K., Gerling, K., Bennett, C. L., Brulé, E., Williams, R. M., Rode, J., & Mankoff, J. (2020). Nothing About Us Without Us: Investigating the Role of Critical Disability Studies in HCI. Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, 1–8. https://doi.org/10.1145/3334480.3375150\n\n\nVirani, A. (2020). Building the Accessible Usability Scale - A Walkthrough. In Fable. https://makeitfable.com/article/building-the-accessible-usability-scale/."
  },
  {
    "objectID": "people.html",
    "href": "people.html",
    "title": "People",
    "section": "",
    "text": "Dr. JooYoung Seo leads the (x)Ability Design Lab, where their research focuses on accessibility research. He is an assistant professor in the School of Information Sciences and a faculty affiliate in the Department of Computer Science, Informatics Institute, and the National Center for Supercomputing Applications at the University of Illinois Urbana-Champaign. Seo is also an RStudio double-certified data science instructor and accessibility expert certified by the International Association of Accessibility Professionals (IAAP). His research topics involve accessible computing, universal design, inclusive data science, and equitable healthcare technologies. As an emerging learning scientist and information scientist, his research focuses particularly on how to make computational literacy more accessible to people with dis/abilities by using multimodal data representation.\nHe has worked on various research and development projects on accessible computing and open-source data science packages (e.g., gt; shiny; rmarkdown to name a few) for accessibility. His research projects have involved not just web accessibility, but also human-centered design and development studies, including inclusive makerspaces, tangible block-based programming, accessible data science (e.g., data tactualization, sonification, and verbalization), and accessible/reproducible scientific writing tools for people with and without dis/abilities.\nHis research is funded by national institutes, industrial partners, and academic society, such as Institute of Museum and Library Services (IMLS), National Science Foundation (NSF), National Institute on Disability, Independent Living, and Rehabilitation Research (NIDILRR), Posit Software, PBC (formerly RStudio), Teach Access, and the International Society of the Learning Sciences (ISLS) and the Wallace Foundation.\nSeo obtained his PhD and M.Ed in at the Pennsylvania State University, and double BA in education and English literature from Sungkyunkwan University, Seoul, South Korea."
  },
  {
    "objectID": "people.html#principal-investigator",
    "href": "people.html#principal-investigator",
    "title": "People",
    "section": "",
    "text": "Dr. JooYoung Seo leads the (x)Ability Design Lab, where their research focuses on accessibility research. He is an assistant professor in the School of Information Sciences and a faculty affiliate in the Department of Computer Science, Informatics Institute, and the National Center for Supercomputing Applications at the University of Illinois Urbana-Champaign. Seo is also an RStudio double-certified data science instructor and accessibility expert certified by the International Association of Accessibility Professionals (IAAP). His research topics involve accessible computing, universal design, inclusive data science, and equitable healthcare technologies. As an emerging learning scientist and information scientist, his research focuses particularly on how to make computational literacy more accessible to people with dis/abilities by using multimodal data representation.\nHe has worked on various research and development projects on accessible computing and open-source data science packages (e.g., gt; shiny; rmarkdown to name a few) for accessibility. His research projects have involved not just web accessibility, but also human-centered design and development studies, including inclusive makerspaces, tangible block-based programming, accessible data science (e.g., data tactualization, sonification, and verbalization), and accessible/reproducible scientific writing tools for people with and without dis/abilities.\nHis research is funded by national institutes, industrial partners, and academic society, such as Institute of Museum and Library Services (IMLS), National Science Foundation (NSF), National Institute on Disability, Independent Living, and Rehabilitation Research (NIDILRR), Posit Software, PBC (formerly RStudio), Teach Access, and the International Society of the Learning Sciences (ISLS) and the Wallace Foundation.\nSeo obtained his PhD and M.Ed in at the Pennsylvania State University, and double BA in education and English literature from Sungkyunkwan University, Seoul, South Korea."
  },
  {
    "objectID": "people.html#ph.d.-students",
    "href": "people.html#ph.d.-students",
    "title": "People",
    "section": "Ph.D. Students",
    "text": "Ph.D. Students\n\n\n\n\n\n\nSanchita Kamath\n\n\nPh.D. Student, Information Sciences\n\n\n\n\nHer research focuses on designing and developing immersive, user-centered solutions that enhance accessibility and inclusivity, particularly for blind and low-vision (BLV) individuals. With a background in Computer Science and Engineering, Sanchita’s work seeks to bridge the gap between cutting-edge technology and user experience. She is currently workign on studies that investigate cognition in BLV people and multiple tools and technologies through which this can be achieved.\n\n\n\n\n\n\n\n\n\nAziz Zeidieh\n\n\nPh.D. Student, Informatics\n\n\n\n\nHis research is an exploration at the crossroads of accessibility, security, privacy, and usability. Within this dynamic realm, he delves into the intricacies of both time-honored and cutting-edge authentication methods, seeking to unlock their true potential for low vision or blind individuals. In parallel, he commits his expertise to visionary projects encompassing multimodal data representation, the battle against misinformation, and the immersive realm of extended reality (XR) in sports — all with a dedicated focus on innovating inclusive experiences for low vision or blind audiences."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "(x)Ability Design Lab",
    "section": "",
    "text": "Welcome to the (x)Ability Design Lab, pronounced as “Accessibility Design” Lab, where the “x” embodies our mission to enhance user experience (UX) and learning experience (LX) by dismantling sociotechnical barriers associated with disability. At our core, we believe in focusing on the ability and experience of all individuals, moving beyond the constraints of traditional accessibility discourse."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact Us",
    "section": "",
    "text": "If you would like to discuss a project or have any questions, please feel free to email us at xability-lab@illinois.edu."
  }
]